{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.feature_extraction.text  import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy import sparse\n",
    "import re\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv').fillna(' ')\n",
    "test  = pd.read_csv('test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text  = test['comment_text']\n",
    "all_text = pd.concat([train_text,test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review) \n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    # to improve execution time this conversion should be done once\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "     \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 159571\n",
      "\n",
      "Review 2000 of 159571\n",
      "\n",
      "Review 3000 of 159571\n",
      "\n",
      "Review 4000 of 159571\n",
      "\n",
      "Review 5000 of 159571\n",
      "\n",
      "Review 6000 of 159571\n",
      "\n",
      "Review 7000 of 159571\n",
      "\n",
      "Review 8000 of 159571\n",
      "\n",
      "Review 9000 of 159571\n",
      "\n",
      "Review 10000 of 159571\n",
      "\n",
      "Review 11000 of 159571\n",
      "\n",
      "Review 12000 of 159571\n",
      "\n",
      "Review 13000 of 159571\n",
      "\n",
      "Review 14000 of 159571\n",
      "\n",
      "Review 15000 of 159571\n",
      "\n",
      "Review 16000 of 159571\n",
      "\n",
      "Review 17000 of 159571\n",
      "\n",
      "Review 18000 of 159571\n",
      "\n",
      "Review 19000 of 159571\n",
      "\n",
      "Review 20000 of 159571\n",
      "\n",
      "Review 21000 of 159571\n",
      "\n",
      "Review 22000 of 159571\n",
      "\n",
      "Review 23000 of 159571\n",
      "\n",
      "Review 24000 of 159571\n",
      "\n",
      "Review 25000 of 159571\n",
      "\n",
      "Review 26000 of 159571\n",
      "\n",
      "Review 27000 of 159571\n",
      "\n",
      "Review 28000 of 159571\n",
      "\n",
      "Review 29000 of 159571\n",
      "\n",
      "Review 30000 of 159571\n",
      "\n",
      "Review 31000 of 159571\n",
      "\n",
      "Review 32000 of 159571\n",
      "\n",
      "Review 33000 of 159571\n",
      "\n",
      "Review 34000 of 159571\n",
      "\n",
      "Review 35000 of 159571\n",
      "\n",
      "Review 36000 of 159571\n",
      "\n",
      "Review 37000 of 159571\n",
      "\n",
      "Review 38000 of 159571\n",
      "\n",
      "Review 39000 of 159571\n",
      "\n",
      "Review 40000 of 159571\n",
      "\n",
      "Review 41000 of 159571\n",
      "\n",
      "Review 42000 of 159571\n",
      "\n",
      "Review 43000 of 159571\n",
      "\n",
      "Review 44000 of 159571\n",
      "\n",
      "Review 45000 of 159571\n",
      "\n",
      "Review 46000 of 159571\n",
      "\n",
      "Review 47000 of 159571\n",
      "\n",
      "Review 48000 of 159571\n",
      "\n",
      "Review 49000 of 159571\n",
      "\n",
      "Review 50000 of 159571\n",
      "\n",
      "Review 51000 of 159571\n",
      "\n",
      "Review 52000 of 159571\n",
      "\n",
      "Review 53000 of 159571\n",
      "\n",
      "Review 54000 of 159571\n",
      "\n",
      "Review 55000 of 159571\n",
      "\n",
      "Review 56000 of 159571\n",
      "\n",
      "Review 57000 of 159571\n",
      "\n",
      "Review 58000 of 159571\n",
      "\n",
      "Review 59000 of 159571\n",
      "\n",
      "Review 60000 of 159571\n",
      "\n",
      "Review 61000 of 159571\n",
      "\n",
      "Review 62000 of 159571\n",
      "\n",
      "Review 63000 of 159571\n",
      "\n",
      "Review 64000 of 159571\n",
      "\n",
      "Review 65000 of 159571\n",
      "\n",
      "Review 66000 of 159571\n",
      "\n",
      "Review 67000 of 159571\n",
      "\n",
      "Review 68000 of 159571\n",
      "\n",
      "Review 69000 of 159571\n",
      "\n",
      "Review 70000 of 159571\n",
      "\n",
      "Review 71000 of 159571\n",
      "\n",
      "Review 72000 of 159571\n",
      "\n",
      "Review 73000 of 159571\n",
      "\n",
      "Review 74000 of 159571\n",
      "\n",
      "Review 75000 of 159571\n",
      "\n",
      "Review 76000 of 159571\n",
      "\n",
      "Review 77000 of 159571\n",
      "\n",
      "Review 78000 of 159571\n",
      "\n",
      "Review 79000 of 159571\n",
      "\n",
      "Review 80000 of 159571\n",
      "\n",
      "Review 81000 of 159571\n",
      "\n",
      "Review 82000 of 159571\n",
      "\n",
      "Review 83000 of 159571\n",
      "\n",
      "Review 84000 of 159571\n",
      "\n",
      "Review 85000 of 159571\n",
      "\n",
      "Review 86000 of 159571\n",
      "\n",
      "Review 87000 of 159571\n",
      "\n",
      "Review 88000 of 159571\n",
      "\n",
      "Review 89000 of 159571\n",
      "\n",
      "Review 90000 of 159571\n",
      "\n",
      "Review 91000 of 159571\n",
      "\n",
      "Review 92000 of 159571\n",
      "\n",
      "Review 93000 of 159571\n",
      "\n",
      "Review 94000 of 159571\n",
      "\n",
      "Review 95000 of 159571\n",
      "\n",
      "Review 96000 of 159571\n",
      "\n",
      "Review 97000 of 159571\n",
      "\n",
      "Review 98000 of 159571\n",
      "\n",
      "Review 99000 of 159571\n",
      "\n",
      "Review 100000 of 159571\n",
      "\n",
      "Review 101000 of 159571\n",
      "\n",
      "Review 102000 of 159571\n",
      "\n",
      "Review 103000 of 159571\n",
      "\n",
      "Review 104000 of 159571\n",
      "\n",
      "Review 105000 of 159571\n",
      "\n",
      "Review 106000 of 159571\n",
      "\n",
      "Review 107000 of 159571\n",
      "\n",
      "Review 108000 of 159571\n",
      "\n",
      "Review 109000 of 159571\n",
      "\n",
      "Review 110000 of 159571\n",
      "\n",
      "Review 111000 of 159571\n",
      "\n",
      "Review 112000 of 159571\n",
      "\n",
      "Review 113000 of 159571\n",
      "\n",
      "Review 114000 of 159571\n",
      "\n",
      "Review 115000 of 159571\n",
      "\n",
      "Review 116000 of 159571\n",
      "\n",
      "Review 117000 of 159571\n",
      "\n",
      "Review 118000 of 159571\n",
      "\n",
      "Review 119000 of 159571\n",
      "\n",
      "Review 120000 of 159571\n",
      "\n",
      "Review 121000 of 159571\n",
      "\n",
      "Review 122000 of 159571\n",
      "\n",
      "Review 123000 of 159571\n",
      "\n",
      "Review 124000 of 159571\n",
      "\n",
      "Review 125000 of 159571\n",
      "\n",
      "Review 126000 of 159571\n",
      "\n",
      "Review 127000 of 159571\n",
      "\n",
      "Review 128000 of 159571\n",
      "\n",
      "Review 129000 of 159571\n",
      "\n",
      "Review 130000 of 159571\n",
      "\n",
      "Review 131000 of 159571\n",
      "\n",
      "Review 132000 of 159571\n",
      "\n",
      "Review 133000 of 159571\n",
      "\n",
      "Review 134000 of 159571\n",
      "\n",
      "Review 135000 of 159571\n",
      "\n",
      "Review 136000 of 159571\n",
      "\n",
      "Review 137000 of 159571\n",
      "\n",
      "Review 138000 of 159571\n",
      "\n",
      "Review 139000 of 159571\n",
      "\n",
      "Review 140000 of 159571\n",
      "\n",
      "Review 141000 of 159571\n",
      "\n",
      "Review 142000 of 159571\n",
      "\n",
      "Review 143000 of 159571\n",
      "\n",
      "Review 144000 of 159571\n",
      "\n",
      "Review 145000 of 159571\n",
      "\n",
      "Review 146000 of 159571\n",
      "\n",
      "Review 147000 of 159571\n",
      "\n",
      "Review 148000 of 159571\n",
      "\n",
      "Review 149000 of 159571\n",
      "\n",
      "Review 150000 of 159571\n",
      "\n",
      "Review 151000 of 159571\n",
      "\n",
      "Review 152000 of 159571\n",
      "\n",
      "Review 153000 of 159571\n",
      "\n",
      "Review 154000 of 159571\n",
      "\n",
      "Review 155000 of 159571\n",
      "\n",
      "Review 156000 of 159571\n",
      "\n",
      "Review 157000 of 159571\n",
      "\n",
      "Review 158000 of 159571\n",
      "\n",
      "Review 159000 of 159571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_train_comments = []\n",
    "num_train = len(train_text)\n",
    "for i in range( 0, num_train ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Review %d of %d\\n\" % ( i+1, num_train ))                                                                    \n",
    "    clean_train_comments.append( review_to_words(train_text[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 153164\n",
      "\n",
      "Review 2000 of 153164\n",
      "\n",
      "Review 3000 of 153164\n",
      "\n",
      "Review 4000 of 153164\n",
      "\n",
      "Review 5000 of 153164\n",
      "\n",
      "Review 6000 of 153164\n",
      "\n",
      "Review 7000 of 153164\n",
      "\n",
      "Review 8000 of 153164\n",
      "\n",
      "Review 9000 of 153164\n",
      "\n",
      "Review 10000 of 153164\n",
      "\n",
      "Review 11000 of 153164\n",
      "\n",
      "Review 12000 of 153164\n",
      "\n",
      "Review 13000 of 153164\n",
      "\n",
      "Review 14000 of 153164\n",
      "\n",
      "Review 15000 of 153164\n",
      "\n",
      "Review 16000 of 153164\n",
      "\n",
      "Review 17000 of 153164\n",
      "\n",
      "Review 18000 of 153164\n",
      "\n",
      "Review 19000 of 153164\n",
      "\n",
      "Review 20000 of 153164\n",
      "\n",
      "Review 21000 of 153164\n",
      "\n",
      "Review 22000 of 153164\n",
      "\n",
      "Review 23000 of 153164\n",
      "\n",
      "Review 24000 of 153164\n",
      "\n",
      "Review 25000 of 153164\n",
      "\n",
      "Review 26000 of 153164\n",
      "\n",
      "Review 27000 of 153164\n",
      "\n",
      "Review 28000 of 153164\n",
      "\n",
      "Review 29000 of 153164\n",
      "\n",
      "Review 30000 of 153164\n",
      "\n",
      "Review 31000 of 153164\n",
      "\n",
      "Review 32000 of 153164\n",
      "\n",
      "Review 33000 of 153164\n",
      "\n",
      "Review 34000 of 153164\n",
      "\n",
      "Review 35000 of 153164\n",
      "\n",
      "Review 36000 of 153164\n",
      "\n",
      "Review 37000 of 153164\n",
      "\n",
      "Review 38000 of 153164\n",
      "\n",
      "Review 39000 of 153164\n",
      "\n",
      "Review 40000 of 153164\n",
      "\n",
      "Review 41000 of 153164\n",
      "\n",
      "Review 42000 of 153164\n",
      "\n",
      "Review 43000 of 153164\n",
      "\n",
      "Review 44000 of 153164\n",
      "\n",
      "Review 45000 of 153164\n",
      "\n",
      "Review 46000 of 153164\n",
      "\n",
      "Review 47000 of 153164\n",
      "\n",
      "Review 48000 of 153164\n",
      "\n",
      "Review 49000 of 153164\n",
      "\n",
      "Review 50000 of 153164\n",
      "\n",
      "Review 51000 of 153164\n",
      "\n",
      "Review 52000 of 153164\n",
      "\n",
      "Review 53000 of 153164\n",
      "\n",
      "Review 54000 of 153164\n",
      "\n",
      "Review 55000 of 153164\n",
      "\n",
      "Review 56000 of 153164\n",
      "\n",
      "Review 57000 of 153164\n",
      "\n",
      "Review 58000 of 153164\n",
      "\n",
      "Review 59000 of 153164\n",
      "\n",
      "Review 60000 of 153164\n",
      "\n",
      "Review 61000 of 153164\n",
      "\n",
      "Review 62000 of 153164\n",
      "\n",
      "Review 63000 of 153164\n",
      "\n",
      "Review 64000 of 153164\n",
      "\n",
      "Review 65000 of 153164\n",
      "\n",
      "Review 66000 of 153164\n",
      "\n",
      "Review 67000 of 153164\n",
      "\n",
      "Review 68000 of 153164\n",
      "\n",
      "Review 69000 of 153164\n",
      "\n",
      "Review 70000 of 153164\n",
      "\n",
      "Review 71000 of 153164\n",
      "\n",
      "Review 72000 of 153164\n",
      "\n",
      "Review 73000 of 153164\n",
      "\n",
      "Review 74000 of 153164\n",
      "\n",
      "Review 75000 of 153164\n",
      "\n",
      "Review 76000 of 153164\n",
      "\n",
      "Review 77000 of 153164\n",
      "\n",
      "Review 78000 of 153164\n",
      "\n",
      "Review 79000 of 153164\n",
      "\n",
      "Review 80000 of 153164\n",
      "\n",
      "Review 81000 of 153164\n",
      "\n",
      "Review 82000 of 153164\n",
      "\n",
      "Review 83000 of 153164\n",
      "\n",
      "Review 84000 of 153164\n",
      "\n",
      "Review 85000 of 153164\n",
      "\n",
      "Review 86000 of 153164\n",
      "\n",
      "Review 87000 of 153164\n",
      "\n",
      "Review 88000 of 153164\n",
      "\n",
      "Review 89000 of 153164\n",
      "\n",
      "Review 90000 of 153164\n",
      "\n",
      "Review 91000 of 153164\n",
      "\n",
      "Review 92000 of 153164\n",
      "\n",
      "Review 93000 of 153164\n",
      "\n",
      "Review 94000 of 153164\n",
      "\n",
      "Review 95000 of 153164\n",
      "\n",
      "Review 96000 of 153164\n",
      "\n",
      "Review 97000 of 153164\n",
      "\n",
      "Review 98000 of 153164\n",
      "\n",
      "Review 99000 of 153164\n",
      "\n",
      "Review 100000 of 153164\n",
      "\n",
      "Review 101000 of 153164\n",
      "\n",
      "Review 102000 of 153164\n",
      "\n",
      "Review 103000 of 153164\n",
      "\n",
      "Review 104000 of 153164\n",
      "\n",
      "Review 105000 of 153164\n",
      "\n",
      "Review 106000 of 153164\n",
      "\n",
      "Review 107000 of 153164\n",
      "\n",
      "Review 108000 of 153164\n",
      "\n",
      "Review 109000 of 153164\n",
      "\n",
      "Review 110000 of 153164\n",
      "\n",
      "Review 111000 of 153164\n",
      "\n",
      "Review 112000 of 153164\n",
      "\n",
      "Review 113000 of 153164\n",
      "\n",
      "Review 114000 of 153164\n",
      "\n",
      "Review 115000 of 153164\n",
      "\n",
      "Review 116000 of 153164\n",
      "\n",
      "Review 117000 of 153164\n",
      "\n",
      "Review 118000 of 153164\n",
      "\n",
      "Review 119000 of 153164\n",
      "\n",
      "Review 120000 of 153164\n",
      "\n",
      "Review 121000 of 153164\n",
      "\n",
      "Review 122000 of 153164\n",
      "\n",
      "Review 123000 of 153164\n",
      "\n",
      "Review 124000 of 153164\n",
      "\n",
      "Review 125000 of 153164\n",
      "\n",
      "Review 126000 of 153164\n",
      "\n",
      "Review 127000 of 153164\n",
      "\n",
      "Review 128000 of 153164\n",
      "\n",
      "Review 129000 of 153164\n",
      "\n",
      "Review 130000 of 153164\n",
      "\n",
      "Review 131000 of 153164\n",
      "\n",
      "Review 132000 of 153164\n",
      "\n",
      "Review 133000 of 153164\n",
      "\n",
      "Review 134000 of 153164\n",
      "\n",
      "Review 135000 of 153164\n",
      "\n",
      "Review 136000 of 153164\n",
      "\n",
      "Review 137000 of 153164\n",
      "\n",
      "Review 138000 of 153164\n",
      "\n",
      "Review 139000 of 153164\n",
      "\n",
      "Review 140000 of 153164\n",
      "\n",
      "Review 141000 of 153164\n",
      "\n",
      "Review 142000 of 153164\n",
      "\n",
      "Review 143000 of 153164\n",
      "\n",
      "Review 144000 of 153164\n",
      "\n",
      "Review 145000 of 153164\n",
      "\n",
      "Review 146000 of 153164\n",
      "\n",
      "Review 147000 of 153164\n",
      "\n",
      "Review 148000 of 153164\n",
      "\n",
      "Review 149000 of 153164\n",
      "\n",
      "Review 150000 of 153164\n",
      "\n",
      "Review 151000 of 153164\n",
      "\n",
      "Review 152000 of 153164\n",
      "\n",
      "Review 153000 of 153164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_test_comments = []\n",
    "num_test = len(test_text)\n",
    "for i in range( 0, num_test ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Review %d of %d\\n\" % ( i+1, num_test ))                                                                    \n",
    "    clean_test_comments.append( review_to_words( test_text[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation edits made username hardcore metallica fan reverted vandalisms closure gas voted new york dolls fac please remove template talk page since retired',\n",
       " 'aww matches background colour seemingly stuck thanks talk january utc']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_comments[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':Dear god this site is horrible.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yo bitch ja rule succesful ever whats hating sad mofuckas bitch slap ur pethedic white faces get kiss ass guys sicken ja rule pride da music man dont diss shit nothin wrong bein like tupac brother fuckin white boys get things right next time',\n",
       " 'rfc title fine imo',\n",
       " 'sources zawe ashton lapland',\n",
       " 'look back source information updated correct form guess source updated shall update information thank message',\n",
       " 'anonymously edit articles',\n",
       " 'thank understanding think highly would revert without discussion',\n",
       " 'please add nonsense wikipedia edits considered vandalism quickly undone would like experiment please use sandbox instead thank']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_comments[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "# Note that CountVectorizer comes with its own options to automatically do preprocessing, tokenization, and stop word removal -- for each of these, instead of specifying \"None\", we could have used a built-in method or specified our own function to use.\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_comments)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 5000)\n"
     ]
    }
   ],
   "source": [
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(train_data_features, Y, test_size = 0.3, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111699, 5000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47872, 5000)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143038</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101451</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63154</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57789</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13053</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "54568       0             0        0       0       0              0\n",
       "3786        0             0        0       0       0              0\n",
       "22938       0             0        0       0       0              0\n",
       "137856      0             0        0       0       0              0\n",
       "143038      0             0        0       0       0              0\n",
       "101451      0             0        0       0       0              0\n",
       "58349       0             0        0       0       0              0\n",
       "63154       1             1        1       1       1              0\n",
       "83999       0             0        0       0       0              0\n",
       "156706      0             0        0       0       0              0\n",
       "107336      0             0        0       0       0              0\n",
       "57789       0             0        0       0       0              0\n",
       "13053       1             0        1       0       1              0\n",
       "36837       0             0        0       0       0              0\n",
       "112373      0             0        0       0       0              0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-a4a3248fe99d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_text_nostem.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/athena/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.savetxt(\"train_text_nostem.csv\", X_train, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"valid_text_nostem.csv\", X_test, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"test_text_nostem.csv\", clean_test_comments, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('~/Downloads/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'darn', 0.7856366038322449),\n",
       " (u'goddamn', 0.7490436434745789),\n",
       " (u'freakin', 0.7200237512588501),\n",
       " (u'fucking', 0.7125218510627747),\n",
       " (u'dang', 0.711518406867981),\n",
       " (u'darned', 0.7037780284881592),\n",
       " (u'damned', 0.7014271020889282),\n",
       " (u'friggin', 0.699498176574707),\n",
       " (u'shit', 0.6993836760520935),\n",
       " (u'dammit', 0.6927375197410583)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('damn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0078125 , -0.07080078,  0.03320312, -0.00714111,  0.04370117,\n",
       "        0.27929688, -0.08837891, -0.05395508,  0.0625    ,  0.08398438,\n",
       "       -0.12011719, -0.15722656, -0.03515625, -0.01342773,  0.07324219,\n",
       "        0.21875   , -0.0300293 , -0.07617188, -0.17871094, -0.35351562,\n",
       "       -0.03686523,  0.06787109,  0.46875   , -0.06884766,  0.10888672,\n",
       "        0.20996094, -0.22265625, -0.04663086,  0.11279297, -0.09375   ,\n",
       "        0.06079102,  0.05761719, -0.05151367,  0.08789062, -0.00238037,\n",
       "        0.02258301,  0.34960938,  0.0050354 ,  0.01599121,  0.04833984,\n",
       "        0.11132812, -0.16308594,  0.34179688,  0.02746582, -0.1875    ,\n",
       "       -0.15625   , -0.0045166 , -0.00601196, -0.24902344,  0.26171875,\n",
       "       -0.328125  , -0.01556396, -0.20117188,  0.24511719, -0.13964844,\n",
       "        0.0859375 , -0.17871094, -0.20507812,  0.1484375 , -0.00830078,\n",
       "        0.06347656,  0.21484375, -0.06396484, -0.03173828, -0.06933594,\n",
       "       -0.03063965,  0.08398438, -0.03149414, -0.234375  ,  0.17578125,\n",
       "        0.27929688,  0.08642578, -0.03039551,  0.07617188, -0.27734375,\n",
       "        0.06933594,  0.19140625,  0.23828125,  0.10009766,  0.25      ,\n",
       "       -0.16308594,  0.25      , -0.11621094, -0.23925781, -0.14257812,\n",
       "        0.265625  ,  0.08642578,  0.41992188,  0.2890625 ,  0.02832031,\n",
       "       -0.23828125,  0.10546875, -0.26367188, -0.08007812, -0.17285156,\n",
       "        0.0279541 ,  0.15234375,  0.19824219,  0.20410156, -0.16113281,\n",
       "       -0.203125  , -0.07958984,  0.07226562, -0.41796875, -0.05786133,\n",
       "       -0.05297852, -0.20019531,  0.10888672,  0.08642578, -0.02954102,\n",
       "       -0.1953125 , -0.35546875,  0.21972656,  0.109375  ,  0.04174805,\n",
       "       -0.13769531, -0.03149414, -0.265625  , -0.03125   , -0.01495361,\n",
       "       -0.16796875, -0.00921631, -0.22558594, -0.09082031,  0.12988281,\n",
       "       -0.20898438, -0.45703125,  0.15527344,  0.09033203, -0.24707031,\n",
       "       -0.18261719,  0.0067749 ,  0.12597656,  0.36132812, -0.00753784,\n",
       "        0.03930664, -0.01251221,  0.06787109,  0.03662109,  0.09814453,\n",
       "        0.27929688, -0.13867188,  0.09814453, -0.06738281, -0.04858398,\n",
       "       -0.1484375 , -0.10058594,  0.01721191, -0.03662109, -0.21777344,\n",
       "        0.39257812,  0.2734375 , -0.03344727, -0.0703125 , -0.19628906,\n",
       "        0.03955078, -0.27148438,  0.18457031,  0.10351562, -0.11572266,\n",
       "       -0.03979492,  0.02819824,  0.21191406,  0.16210938, -0.33789062,\n",
       "       -0.34960938, -0.05249023, -0.2734375 ,  0.05932617,  0.1171875 ,\n",
       "        0.09960938, -0.10253906,  0.2421875 , -0.01275635, -0.30664062,\n",
       "       -0.07470703,  0.41992188, -0.15429688, -0.20898438,  0.36914062,\n",
       "        0.30078125, -0.01141357,  0.00346375,  0.40234375, -0.02319336,\n",
       "        0.23046875,  0.09277344,  0.11376953, -0.00921631, -0.07373047,\n",
       "        0.24023438, -0.09179688,  0.09130859,  0.30273438,  0.13378906,\n",
       "        0.20703125, -0.15429688, -0.03613281, -0.04736328,  0.00257874,\n",
       "       -0.12060547, -0.02819824, -0.24023438, -0.03466797, -0.09570312,\n",
       "       -0.06835938, -0.17285156,  0.22753906, -0.22363281,  0.05786133,\n",
       "       -0.12890625,  0.23632812,  0.12158203, -0.22167969,  0.04858398,\n",
       "        0.19921875,  0.11669922, -0.18554688, -0.2578125 , -0.00418091,\n",
       "       -0.03222656,  0.3671875 ,  0.40625   ,  0.19824219,  0.20996094,\n",
       "       -0.07714844,  0.26171875,  0.30078125, -0.10400391, -0.22265625,\n",
       "       -0.14160156,  0.0534668 , -0.13769531,  0.14453125,  0.15820312,\n",
       "        0.26757812,  0.04785156, -0.07519531,  0.13769531,  0.19921875,\n",
       "        0.38867188,  0.04003906,  0.04736328, -0.14355469,  0.07324219,\n",
       "        0.01831055, -0.06884766,  0.31445312, -0.09179688,  0.12792969,\n",
       "        0.01367188, -0.0324707 , -0.09521484,  0.25976562,  0.04516602,\n",
       "       -0.0168457 , -0.33789062, -0.04858398,  0.00221252, -0.09130859,\n",
       "        0.07714844, -0.11962891, -0.17578125, -0.05151367, -0.01794434,\n",
       "       -0.25585938, -0.2109375 ,  0.01135254, -0.203125  , -0.03662109,\n",
       "       -0.4296875 ,  0.28515625, -0.04418945,  0.23046875,  0.2109375 ,\n",
       "       -0.13964844, -0.12792969,  0.03540039, -0.13574219,  0.3125    ,\n",
       "        0.41796875, -0.17382812,  0.08300781,  0.06787109, -0.08300781,\n",
       "       -0.14160156, -0.12890625, -0.16699219,  0.04785156,  0.09667969,\n",
       "        0.18652344,  0.10742188, -0.40234375,  0.00686646, -0.16992188,\n",
       "       -0.37109375,  0.07275391,  0.00704956, -0.265625  ,  0.00537109],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['bitch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9f6bfc5107f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "## Training the model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test['id'])\n",
    "for target in target_col:\n",
    "    Y_col = Y_train[target]\n",
    "    lr.fit(X_train,Y_train)\n",
    "    submission[target] = lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05,0.005],\n",
    "              'max_depth': [3,4,5,6,7,8,9,10],\n",
    "              'min_child_weight': [1,5,10],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.6,0.8,1.0],\n",
    "              'scale_pos_weight':[18,20,22,24,26,28,30,35,40,45,50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search = GridSearchCV(xgb_model, param_grid=parameters,  scoring='f1', n_jobs=-1, verbose=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'objective':['binary:logistic'],'max_depth':[4], 'silent':[1],'subsample': [0.8], 'scale_pos_weight':[10,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_round = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(xgb_model, param_grid=param,  scoring='f1', n_jobs=-1, verbose=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] objective=binary:logistic, scale_pos_weight=10, silent=1, max_depth=4, subsample=0.8 \n",
      "[CV] objective=binary:logistic, scale_pos_weight=10, silent=1, max_depth=4, subsample=0.8 \n",
      "[CV] objective=binary:logistic, scale_pos_weight=10, silent=1, max_depth=4, subsample=0.8 \n",
      "[CV] objective=binary:logistic, scale_pos_weight=20, silent=1, max_depth=4, subsample=0.8 \n",
      "[CV] objective=binary:logistic, scale_pos_weight=20, silent=1, max_depth=4, subsample=0.8 \n",
      "[CV] objective=binary:logistic, scale_pos_weight=20, silent=1, max_depth=4, subsample=0.8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-63:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    task = get()\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process PoolWorker-65:\n",
      "Process PoolWorker-66:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "  File \"/Users/athena/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    return recv()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-33df27841244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/athena/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/athena/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/athena/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/athena/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/athena/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/athena/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,Y_train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
