{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.feature_extraction.text  import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy import sparse\n",
    "import re\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv').fillna(' ')\n",
    "test  = pd.read_csv('test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95851, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text  = test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = pd.concat([train_text,test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(single_comment):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", single_comment) \n",
    "    words = letters_only.lower().split() \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops] \n",
    "    stemmed_words = [stemmer.stem(w) for w in meaningful_words]\n",
    "    return( \" \".join( stemmed_words ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 95851\n",
      "\n",
      "Review 2000 of 95851\n",
      "\n",
      "Review 3000 of 95851\n",
      "\n",
      "Review 4000 of 95851\n",
      "\n",
      "Review 5000 of 95851\n",
      "\n",
      "Review 6000 of 95851\n",
      "\n",
      "Review 7000 of 95851\n",
      "\n",
      "Review 8000 of 95851\n",
      "\n",
      "Review 9000 of 95851\n",
      "\n",
      "Review 10000 of 95851\n",
      "\n",
      "Review 11000 of 95851\n",
      "\n",
      "Review 12000 of 95851\n",
      "\n",
      "Review 13000 of 95851\n",
      "\n",
      "Review 14000 of 95851\n",
      "\n",
      "Review 15000 of 95851\n",
      "\n",
      "Review 16000 of 95851\n",
      "\n",
      "Review 17000 of 95851\n",
      "\n",
      "Review 18000 of 95851\n",
      "\n",
      "Review 19000 of 95851\n",
      "\n",
      "Review 20000 of 95851\n",
      "\n",
      "Review 21000 of 95851\n",
      "\n",
      "Review 22000 of 95851\n",
      "\n",
      "Review 23000 of 95851\n",
      "\n",
      "Review 24000 of 95851\n",
      "\n",
      "Review 25000 of 95851\n",
      "\n",
      "Review 26000 of 95851\n",
      "\n",
      "Review 27000 of 95851\n",
      "\n",
      "Review 28000 of 95851\n",
      "\n",
      "Review 29000 of 95851\n",
      "\n",
      "Review 30000 of 95851\n",
      "\n",
      "Review 31000 of 95851\n",
      "\n",
      "Review 32000 of 95851\n",
      "\n",
      "Review 33000 of 95851\n",
      "\n",
      "Review 34000 of 95851\n",
      "\n",
      "Review 35000 of 95851\n",
      "\n",
      "Review 36000 of 95851\n",
      "\n",
      "Review 37000 of 95851\n",
      "\n",
      "Review 38000 of 95851\n",
      "\n",
      "Review 39000 of 95851\n",
      "\n",
      "Review 40000 of 95851\n",
      "\n",
      "Review 41000 of 95851\n",
      "\n",
      "Review 42000 of 95851\n",
      "\n",
      "Review 43000 of 95851\n",
      "\n",
      "Review 44000 of 95851\n",
      "\n",
      "Review 45000 of 95851\n",
      "\n",
      "Review 46000 of 95851\n",
      "\n",
      "Review 47000 of 95851\n",
      "\n",
      "Review 48000 of 95851\n",
      "\n",
      "Review 49000 of 95851\n",
      "\n",
      "Review 50000 of 95851\n",
      "\n",
      "Review 51000 of 95851\n",
      "\n",
      "Review 52000 of 95851\n",
      "\n",
      "Review 53000 of 95851\n",
      "\n",
      "Review 54000 of 95851\n",
      "\n",
      "Review 55000 of 95851\n",
      "\n",
      "Review 56000 of 95851\n",
      "\n",
      "Review 57000 of 95851\n",
      "\n",
      "Review 58000 of 95851\n",
      "\n",
      "Review 59000 of 95851\n",
      "\n",
      "Review 60000 of 95851\n",
      "\n",
      "Review 61000 of 95851\n",
      "\n",
      "Review 62000 of 95851\n",
      "\n",
      "Review 63000 of 95851\n",
      "\n",
      "Review 64000 of 95851\n",
      "\n",
      "Review 65000 of 95851\n",
      "\n",
      "Review 66000 of 95851\n",
      "\n",
      "Review 67000 of 95851\n",
      "\n",
      "Review 68000 of 95851\n",
      "\n",
      "Review 69000 of 95851\n",
      "\n",
      "Review 70000 of 95851\n",
      "\n",
      "Review 71000 of 95851\n",
      "\n",
      "Review 72000 of 95851\n",
      "\n",
      "Review 73000 of 95851\n",
      "\n",
      "Review 74000 of 95851\n",
      "\n",
      "Review 75000 of 95851\n",
      "\n",
      "Review 76000 of 95851\n",
      "\n",
      "Review 77000 of 95851\n",
      "\n",
      "Review 78000 of 95851\n",
      "\n",
      "Review 79000 of 95851\n",
      "\n",
      "Review 80000 of 95851\n",
      "\n",
      "Review 81000 of 95851\n",
      "\n",
      "Review 82000 of 95851\n",
      "\n",
      "Review 83000 of 95851\n",
      "\n",
      "Review 84000 of 95851\n",
      "\n",
      "Review 85000 of 95851\n",
      "\n",
      "Review 86000 of 95851\n",
      "\n",
      "Review 87000 of 95851\n",
      "\n",
      "Review 88000 of 95851\n",
      "\n",
      "Review 89000 of 95851\n",
      "\n",
      "Review 90000 of 95851\n",
      "\n",
      "Review 91000 of 95851\n",
      "\n",
      "Review 92000 of 95851\n",
      "\n",
      "Review 93000 of 95851\n",
      "\n",
      "Review 94000 of 95851\n",
      "\n",
      "Review 95000 of 95851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_train_comments = []\n",
    "num_train = len(train_text)\n",
    "for i in range( 0, num_train ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Review %d of %d\\n\" % ( i+1, num_train ))                                                                    \n",
    "    clean_train_comments.append( clean( train_text[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guy Fawkes \\n\\nim a resident in bridgwater and i go to the carnival every year, im wuite dedicated to the town and enjoy alot about it, However, i think you are wrong, although we are rebels i think that the carnvial is to celebrate Guy fawkes getting caught and therfor preventing it, why would you want to celebrate somebody theying to murder out majisty.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'guy fawk im resid bridgwat go carniv everi year im wuit dedic town enjoy alot howev think wrong although rebel think carnvial celebr guy fawk get caught therfor prevent would want celebr somebodi they murder majisti'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_comments[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_word  = TfidfVectorizer(sublinear_tf = True, max_features = 15000,ngram_range=(1,1),stop_words=None,analyzer = 'word',tokenizer=None, preprocessor=None)\n",
    "vect_word2  = TfidfVectorizer(sublinear_tf = True, max_features = 15000,ngram_range=(1,2),stop_words=None,analyzer = 'word',tokenizer=None, preprocessor=None)\n",
    "vect_char  = TfidfVectorizer(sublinear_tf = True, max_features = 20000,stop_words=None,analyzer = 'char',tokenizer=None, preprocessor=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloe/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "vect_word.fit(clean_train_comments)\n",
    "train_word = vect_word.transform(clean_train_comments)\n",
    "X = sparse.hstack([train_word])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloe/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "vect_word.fit(clean_train_comments)\n",
    "train_word = vect_word.transform(clean_train_comments)\n",
    "vect_char.fit(clean_train_comments)\n",
    "train_char = vect_char.transform(clean_train_comments)\n",
    "X = sparse.hstack([train_word, train_char])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_freq = pd.DataFrame({'term': vect_word.get_feature_names(), 'occurrences':np.asarray(train_word.sum(axis=0)).ravel().tolist()})\n",
    "#word_freq['frequency'] = word_freq['occurrences']/np.sum(word_freq['occurrences'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloe/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "vect_word.fit(clean_train_comments)\n",
    "train_word = vect_word.transform(clean_train_comments)\n",
    "vect_char.fit(clean_train_comments)\n",
    "train_char = vect_char.transform(clean_train_comments)\n",
    "vect_word2.fit(clean_train_comments)\n",
    "train_word2 = vect_word2.transform(clean_train_comments)\n",
    "X = sparse.hstack([train_word, train_word2, train_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train = sparse.hstack([train_word,train_vector1,train_vector_char])\n",
    "#X_test  = sparse.hstack([test_vector,test_vector1,test_vector_char])\n",
    "#X_train = sparse.hstack([train_vector,train_vector_char])\n",
    "#X_test  = sparse.hstack([test_vector,test_vector_char])\n",
    "\n",
    "#Y_train = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "#X = sparse.hstack([train_word])\n",
    "\n",
    "\n",
    "X = sparse.hstack([train_word, train_word2, train_char])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size = 0.3, random_state =42  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_col = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95851, 15000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test['id'])\n",
    "for target in target_col:\n",
    "    Y_col = Y_train[target]\n",
    "    lr.fit(X_train,Y_col)\n",
    "    submission[target] = lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.997609</td>\n",
       "      <td>0.171832</td>\n",
       "      <td>0.995936</td>\n",
       "      <td>0.034118</td>\n",
       "      <td>0.944175</td>\n",
       "      <td>0.306862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.001558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.032664</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.997609      0.171832  0.995936  0.034118  0.944175   \n",
       "1  0000247867823ef7  0.006958      0.002642  0.004620  0.000504  0.001299   \n",
       "2  00013b17ad220c46  0.022850      0.001113  0.012370  0.000469  0.006027   \n",
       "3  00017563c3f7919a  0.006423      0.003306  0.003889  0.000724  0.004597   \n",
       "4  00017695ad8997eb  0.032664      0.001663  0.003319  0.001973  0.012162   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.306862  \n",
       "1       0.001176  \n",
       "2       0.001558  \n",
       "3       0.000922  \n",
       "4       0.001672  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0.9710665846220728\n",
      "severe_toxic\n",
      "0.9829155107661988\n",
      "obscene\n",
      "0.9882546687321436\n",
      "threat\n",
      "0.9678713458452521\n",
      "insult\n",
      "0.9758868669054923\n",
      "identity_hate\n",
      "0.9717236438858596\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for target in target_col:\n",
    "    Y_train_col = Y_train[target]\n",
    "    Y_test_col  = Y_test[target]\n",
    "    lr.fit(X_train, Y_train_col)\n",
    "    sum += roc_auc_score( Y_test_col,pd.DataFrame(lr.predict_proba(X_test)[:,1]))\n",
    "    print(target)\n",
    "    print(roc_auc_score( Y_test_col,pd.DataFrame(lr.predict_proba(X_test)[:,1])))\n",
    "sum = sum/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762864367928366"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(sublinear_tf = True, max_features = 60000,ngram_range=(1,2),stop_words=None,analyzer = 'word',tokenizer=None, preprocessor=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=1,\n",
       "        stop_words=None, strip_accents='unicode', sublinear_tf=1,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=1,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.fit(clean_train_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloe/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "train_term = vec.transform(clean_train_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pr(y_i,y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1)/((y == y_i).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(train_term, Y, test_size = 0.3, random_state =42  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = X_train.sign()\n",
    "x_test  = X_test.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y)/pr(0,y))\n",
    "    lr_model= LogisticRegressionCV(Cs=5)\n",
    "    x_nb = x.multiply(r)\n",
    "    return lr_model.fit(x_nb, y), r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.zeros((len(Y_test), len(target_col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "fit severe_toxic\n",
      "fit obscene\n",
      "fit threat\n",
      "fit insult\n",
      "fit identity_hate\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(target_col):\n",
    "    print('fit',j)\n",
    "    m, r = get_model(Y_train[j])\n",
    "    preds[:,i] = m.predict_proba(x_test.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.49868270e-03, 2.98560278e-03, 3.46954205e-04, 1.58838835e-03,\n",
       "        1.91344924e-04, 1.53232748e-05],\n",
       "       [3.67928535e-03, 1.95964033e-03, 9.05174995e-06, 1.14310277e-03,\n",
       "        9.23604447e-05, 1.53608682e-05],\n",
       "       [1.36786132e-05, 3.79157553e-03, 1.91211975e-05, 1.26681032e-03,\n",
       "        5.68340429e-06, 3.89031479e-05],\n",
       "       ...,\n",
       "       [1.00000000e+00, 7.30573220e-01, 1.00000000e+00, 1.19879833e-02,\n",
       "        9.99499622e-01, 3.91713011e-04],\n",
       "       [8.57500980e-03, 3.78909416e-03, 3.98026478e-03, 2.36292210e-03,\n",
       "        3.72995971e-03, 3.46779160e-04],\n",
       "       [2.54360538e-01, 5.51600934e-03, 2.88158626e-02, 2.80371151e-03,\n",
       "        3.26459135e-03, 9.12040384e-05]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.9546119867039577\n",
      "1\n",
      "0.973901156658976\n",
      "2\n",
      "0.973257004080167\n",
      "3\n",
      "0.9681980976301774\n",
      "4\n",
      "0.9570237635440719\n",
      "5\n",
      "0.9469827123418879\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for target in range(6):\n",
    "    Y_test_col  = Y_test.iloc[:,target]\n",
    "    sum += roc_auc_score( Y_test_col,pd.DataFrame(preds[:,target]))\n",
    "    print(target)\n",
    "    print(roc_auc_score( Y_test_col,pd.DataFrame(preds[:,target])))\n",
    "sum = sum/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962329120159873"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.50303387e-02, 2.18453710e-02, 6.31311349e-05, ...,\n",
       "       1.00000000e+00, 4.53097623e-03, 6.94762981e-03])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
